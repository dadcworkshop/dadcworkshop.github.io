<!DOCTYPE html>
<html lang="en-US">

<head>
  <title>
Program
</title>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="icon" href="/favicon/favicon.ico">

  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
  <![endif]-->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KRG38PMVXV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-KRG38PMVXV');
  </script>

</head>

<body>
  <div class="wrapper">
    <header>
      <a href="/"><img src="/img/logo.png" alt="Logo" style="max-width: 45%; margin-bottom: 0.4em;" /></a>

      <h1><a href="/">Dynamic Adversarial Data Collection (DADC) Workshop at NAACL 2022</a></h1>

      <p>The First Workshop on Dynamic Adversarial Data Collection (DADC) at <a href='https://2022.naacl.org/'
          target='_blank'>NAACL 2022</a> in Seattle, Washington.</p>

      <a href="/">Home</a>
      <br />
      <a href="/program">Invited Speakers</a>
      <br />
      <a href="/shared-task">Shared Task</a>
      <br />
      <a href="/call-for-papers">Call for Papers</a>
      <br>
      <a href="https://openreview.net/group?id=aclweb.org/NAACL/2022/Workshop/DADC" target="_blank">Submit Paper</a>
      <br>
      <a href="https://groups.google.com/u/0/g/dadc-workshop" target="_blank">Sign up for notifications</a>
      <br>

      <!-- Twitter Feed -->
      <div class="twitter-feed" style="padding-top: 16px">
        <a class="twitter-timeline" data-height="420" href="https://twitter.com/DADCworkshop?ref_src=twsrc%5Etfw">Tweets
          by DADCworkshop</a>
        <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>
    </header>

    <section>

      
<h1 id="invited-speakers-and-program">Invited Speakers and Program</h1>
<h2 id="invited-speakers"><span style="color:#267CB9"> Invited Speakers </span></h2>
<h3 id="anna-rogers-university-of-copenhagen"><a href="https://annargrs.github.io">Anna Rogers, University of Copenhagen</a></h3>
<ul>
<li><strong>Title: What kinds of questions have we been asking? A taxonomy for QA/RC benchmarks</strong></li>
<li>Abstract: This talk provides an overview of the current landscape of resources for Question Answering and Reading comprehension, highlighting the current lacunae for future work. I will also present a new taxonomy of &quot;skills&quot; targeted by QA/RC datasets and discuss various ways in which questions may be unanswerable.</li>
</ul>
<h3 id="sam-bowman-assistant-professor-new-york-university-visiting-researcher-sabbatical-anthropic"><a href="https://cims.nyu.edu/%7Esbowman/">Sam Bowman, Assistant Professor, New York University &amp; Visiting Researcher (Sabbatical), Anthropic</a></h3>
<ul>
<li><strong>Title: Why Adversarially-Collected Test Sets Donâ€™t Work as Benchmarks</strong></li>
<li>Abstract: Dynamic and/or adversarial data collection can be quite useful as a way of collecting training data for machine-learning models, identifying the conditions under which these models fail, and conducting online head-to-head comparisons between models. However, it is essentially impossible to use these practices to build usable static benchmark datasets for use in evaluating or comparing future new models. I defend this point using a mix of conceptual and empirical points, focusing on the claims (i) that adversarial data collection can skew the distribution of phenomena such as to make it unrepresentative of the intended task, and (ii) that adversarial data collection can arbitrarily shift the rankings of models on its resulting test sets to disfavor systems that are qualitatively similar to the current state of the art.</li>
</ul>
<h3 id="jordan-boyd-graber-associate-professor-university-of-maryland-at-college-park"><a href="http://users.umiacs.umd.edu/%7Ejbg/">Jordan Boyd-Graber, Associate Professor, University of Maryland at College Park</a></h3>
<ul>
<li><strong>Title: Incentives for Experts to Create Adversarial QA and
Fact-Checking Examples</strong></li>
<li>Abstract: I'll discuss two examples of our work putting experienced writers in
front of a retrieval-driven adversarial authoring system: question
writing and fact-checking.  For question answering, we develop a
retrieval-based adversarial authoring platform and create incentives
to get people to use our system in the first place, write
interesting questions humans can answer, and challenge a QA system.
While the best humans lose to computer QA systems on normal questions,
computers struggle to answer our adversarial questions.  We then turn
to fact checking, creating a new game (Fool Me Twice) to solicit
difficult-to-verify claims---that can be either true or false---and to
test how difficult the claims are both for humans and computers.  We
argue that the focus on retrieval is important for knowledge-based
adversarial examples because it highlights diverse information,
prevents frustration in authors, and takes advantage of users'
expertise.</li>
</ul>



    </section>
    <footer>
      <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small>
      </p>
    </footer>
  </div>
  <script src="/js/scale.fix.js"></script>
</body>

</html>